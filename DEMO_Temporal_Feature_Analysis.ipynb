{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c453b156"
   },
   "source": [
    "# Temporal Feature Analysis Demo\n",
    "\n",
    "Welcome to [Temporal Feature Analysis](https://arxiv.org/abs/2511.01836), this notebook demonstrates how to get started.\n",
    "\n",
    "Temporal Feature Analysis is an interpretability method designed to capture both contextual and local information in language model representations. The method is based on the hypothesis that language models build up an aggregate context representation through the input sequence, and each new token provides a sparse update. Specifically, the activation `x_t` at token position `t`is a sum `x_t = x_{p,t} + x_{n,t}` of a representation of context `x_{p,t}` (p for \"predictive\") and a representation of novel informantion `x_{n,t}`. The Figure below illustrates how Temporal Feature Analysis uses an attention layer to predict `x_{p,t}` and a Sparse Autoencoder to reconstruct `x_{n,t} = x_t - x_{p,t}`. We find that the corresponding feature code `z_{p,t}` captures long-term informations, like event boundaries in stories, while `z_{n,t}` captures local concepts similar to existing SAEs. Note: We use the terms *context code* and *predictive code* interchangeably.\n",
    "\n",
    "<div style=\"background-color: white; padding: 10px; display: inline-block;\">\n",
    "  <img src=\"img/architecture.png\" alt=\"Architecture\">\n",
    "</div>\n",
    "\n",
    "**Content of this notebook**\n",
    "\n",
    "- Loading a pretrained Temporal Feature Analyzer (TFA)\n",
    "- Extracting predictive and novel codes from language model activations\n",
    "- Feature dashboard for novel codes\n",
    "- Similarity matrix for predictive codes\n",
    "- UMAP for predictive codes\n",
    "\n",
    "\n",
    "**Learn more**\n",
    "\n",
    "- [Pre-print on Arxiv](https://arxiv.org/abs/2511.01836)\n",
    "- [Interactive demo on Neuronpedia](https://www.neuronpedia.org/gemma-2-2b/12-temporal-res?simMatrixDemo=alice-maya)\n",
    "- [Training repo on GitHub](https://github.com/eslubana/TemporalFeatureAnalysis)\n",
    "- [Pretrained weights on Huggingface](https://huggingface.co/canrager/temporalSAEs/tree/main)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "Run the cells in the following section to setup the notebook environment. Logging in to your Huggingface Account via `notebook_login()` is necessary to load the Gemma-2-2B model. Implementational details of the Temporal Feature Analyzer might be of interest to the reader, otherwise this section mostly contains overhead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install torch transformers datasets huggingface_hub safetensors pyyaml plotly accelerate matplotlib umap-learn nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import yaml\n",
    "from huggingface_hub import hf_hub_download, notebook_login\n",
    "from safetensors.torch import load_file\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from IPython.display import IFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "2396de73138f498db223ce3ae250d304",
      "319a130126744db7867848c37a895830",
      "e6ed5543c73342ccab53dd0efc99acaf",
      "baace5ca39354ea99c2a322aeb6ce288",
      "d877ced046554ae1b6b3c120b617eae8",
      "c69b43b5a7454d6ebb8d33636405a4a1",
      "f1e8bd8a90354705afd7535cb89a46be",
      "0bdc5abb6f7c4d5db244ceb990a18740",
      "8e9380ae1b634a489bdd191cf83388c3",
      "53a9612cc2664cb58000b8d6912fc65b",
      "6de45436c99f4018b7671159addc0078",
      "a56dd982fe12494196afc1430abe02b9",
      "d3cac87a7cbb4a3fb22d40363392c8d5",
      "2fc3c93be27b486faa760dd8d69b14f9",
      "7a9e6f98fc3941a2934ce560c7ac7f04",
      "2723c35b1c114fe6a9d8994af0a12823",
      "c3b1ad9ed1cf4d94b165ca2b9a4811a7",
      "bdab85a532c14a4ba1eb3a5b43725d80",
      "e5d29d9d0647497a9144762284830180",
      "45108dac5a2641828adb9a4a1ddccf02"
     ]
    },
    "id": "YE3jJPewIE5v",
    "outputId": "57887d4e-b165-448c-e786-52e8e0ccef21"
   },
   "outputs": [],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sae_impl"
   },
   "source": [
    "### Temporal SAE Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "attention"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "def get_attention(query: th.Tensor, key: th.Tensor) -> th.Tensor:\n",
    "    L, S = query.size(-2), key.size(-2)\n",
    "    scale_factor = 1 / math.sqrt(query.size(-1))\n",
    "    attn_bias = th.zeros(L, S, dtype=query.dtype, device=query.device)\n",
    "    temp_mask = th.ones(L, S, dtype=th.bool, device=query.device).tril(diagonal=0)\n",
    "    attn_bias.masked_fill_(temp_mask.logical_not(), float(\"-inf\"))\n",
    "    attn_bias.to(query.dtype)\n",
    "\n",
    "    attn_weight = query @ key.transpose(-2, -1) * scale_factor\n",
    "    attn_weight += attn_bias\n",
    "    return th.softmax(attn_weight, dim=-1)\n",
    "\n",
    "\n",
    "class ManualAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Manual implementation to allow tinkering with the attention mechanism.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dimin: int,\n",
    "        n_heads: int = 4,\n",
    "        bottleneck_factor: int = 64,\n",
    "        bias_k: bool = True,\n",
    "        bias_q: bool = True,\n",
    "        bias_v: bool = True,\n",
    "        bias_o: bool = True,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        assert dimin % (bottleneck_factor * n_heads) == 0\n",
    "\n",
    "        # attention heads\n",
    "        self.n_heads = n_heads\n",
    "        self.n_embds = dimin // bottleneck_factor\n",
    "        self.dimin = dimin\n",
    "\n",
    "        # key, query, value projections for all heads, but in a batch\n",
    "        self.k_ctx = nn.Linear(dimin, self.n_embds, bias=bias_k)\n",
    "        self.q_target = nn.Linear(dimin, self.n_embds, bias=bias_q)\n",
    "        self.v_ctx = nn.Linear(dimin, dimin, bias=bias_v)\n",
    "\n",
    "        # output projection\n",
    "        self.c_proj = nn.Linear(dimin, dimin, bias=bias_o)\n",
    "\n",
    "        # Normalize to match scale with representations\n",
    "        with th.no_grad():\n",
    "            scaling = 1 / math.sqrt(self.n_embds // self.n_heads)\n",
    "            self.k_ctx.weight.copy_(\n",
    "                scaling\n",
    "                * self.k_ctx.weight\n",
    "                / (1e-6 + th.linalg.norm(self.k_ctx.weight, dim=1, keepdim=True))\n",
    "            )\n",
    "            self.q_target.weight.copy_(\n",
    "                scaling\n",
    "                * self.q_target.weight\n",
    "                / (1e-6 + th.linalg.norm(self.q_target.weight, dim=1, keepdim=True))\n",
    "            )\n",
    "\n",
    "            scaling = 1 / math.sqrt(self.dimin // self.n_heads)\n",
    "            self.v_ctx.weight.copy_(\n",
    "                scaling\n",
    "                * self.v_ctx.weight\n",
    "                / (1e-6 + th.linalg.norm(self.v_ctx.weight, dim=1, keepdim=True))\n",
    "            )\n",
    "\n",
    "            scaling = 1 / math.sqrt(self.dimin)\n",
    "            self.c_proj.weight.copy_(\n",
    "                scaling\n",
    "                * self.c_proj.weight\n",
    "                / (1e-6 + th.linalg.norm(self.c_proj.weight, dim=1, keepdim=True))\n",
    "            )\n",
    "\n",
    "    def forward(\n",
    "        self, x_ctx: th.Tensor, x_target: th.Tensor, get_attn_map: bool = False\n",
    "    ) -> tuple[th.Tensor, th.Tensor | None]:\n",
    "        \"\"\"\n",
    "        Compute projective attention output\n",
    "        \"\"\"\n",
    "        # Compute key and value projections from context representations\n",
    "        k = self.k_ctx(x_ctx)\n",
    "        v = self.v_ctx(x_ctx)\n",
    "\n",
    "        # Compute query projection from target representations\n",
    "        q = self.q_target(x_target)\n",
    "\n",
    "        # Split into heads\n",
    "        B, T, _ = x_ctx.size()\n",
    "        k = k.view(B, T, self.n_heads, self.n_embds // self.n_heads).transpose(1, 2)\n",
    "        q = q.view(B, T, self.n_heads, self.n_embds // self.n_heads).transpose(1, 2)\n",
    "        v = v.view(B, T, self.n_heads, self.dimin // self.n_heads).transpose(1, 2)\n",
    "\n",
    "        # Attn map\n",
    "        attn_map: th.Tensor | None = None\n",
    "        if get_attn_map:\n",
    "            attn_map = get_attention(query=q, key=k)\n",
    "            th.cuda.empty_cache()\n",
    "\n",
    "        # Scaled dot-product attention\n",
    "        attn_output = th.nn.functional.scaled_dot_product_attention(\n",
    "            q, k, v, attn_mask=None, dropout_p=0, is_causal=True\n",
    "        )\n",
    "\n",
    "        # Reshape, project back to original dimension\n",
    "        d_target = self.c_proj(\n",
    "            attn_output.transpose(1, 2).contiguous().view(B, T, self.dimin)\n",
    "        )\n",
    "\n",
    "        if get_attn_map:\n",
    "            return d_target, attn_map\n",
    "        return d_target, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "temporal_sae"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "class TemporalSAE(th.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dimin: int = 2304,\n",
    "        width: int = 9216,\n",
    "        n_heads: int = 4,\n",
    "        sae_diff_type: str = \"topk\",\n",
    "        kval_topk: int | None = 192,\n",
    "        tied_weights: bool = True,\n",
    "        n_attn_layers: int = 1,\n",
    "        bottleneck_factor: int = 1,\n",
    "        activation_scaling_factor: float = 0.00666666667,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.sae_type = \"temporal\"\n",
    "        self.width = width\n",
    "        self.dimin = dimin\n",
    "        self.eps = 1e-6\n",
    "        self.lam = 1 / (4 * dimin)\n",
    "        self.tied_weights = tied_weights\n",
    "        self.activation_scaling_factor = activation_scaling_factor\n",
    "\n",
    "        ## Attention parameters\n",
    "        self.n_attn_layers = n_attn_layers\n",
    "        self.attn_layers = nn.ModuleList(\n",
    "            [\n",
    "                ManualAttention(\n",
    "                    dimin=width,\n",
    "                    n_heads=n_heads,\n",
    "                    bottleneck_factor=bottleneck_factor,\n",
    "                    bias_k=True,\n",
    "                    bias_q=True,\n",
    "                    bias_v=True,\n",
    "                    bias_o=True,\n",
    "                )\n",
    "                for _ in range(n_attn_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        ## Dictionary parameters\n",
    "        self.D = nn.Parameter(th.randn((width, dimin)))\n",
    "        self.b = nn.Parameter(th.zeros((dimin)))\n",
    "        if not tied_weights:\n",
    "            self.E = nn.Parameter(th.randn((dimin, width)))\n",
    "\n",
    "        ## SAE-specific parameters\n",
    "        self.sae_diff_type = sae_diff_type\n",
    "        self.kval_topk = kval_topk if sae_diff_type == \"topk\" else None\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x_input: th.Tensor,\n",
    "        return_graph: bool = False,\n",
    "        inf_k: int | None = None,\n",
    "    ) -> tuple[th.Tensor, dict[str, th.Tensor | None]]:\n",
    "        B, L, _ = x_input.size()\n",
    "        E = self.D.T if self.tied_weights else self.E\n",
    "\n",
    "        ### Define context and target ###\n",
    "        x_input = x_input * self.activation_scaling_factor\n",
    "        x_input = x_input - self.b\n",
    "\n",
    "        ### Tracking variables ###\n",
    "        attn_graphs = []\n",
    "\n",
    "        ### Predictable part ###\n",
    "        z_pred = th.zeros(\n",
    "            (B, L, self.width), device=x_input.device, dtype=x_input.dtype\n",
    "        )\n",
    "        for attn_layer in self.attn_layers:\n",
    "            z_input = F.relu(th.matmul(x_input * self.lam, E))\n",
    "            z_ctx = th.cat(\n",
    "                (th.zeros_like(z_input[:, :1, :]), z_input[:, :-1, :].clone()), dim=1\n",
    "            )\n",
    "\n",
    "            # Compute codes using attention\n",
    "            z_pred_, attn_graphs_ = attn_layer(\n",
    "                z_ctx, z_input, get_attn_map=return_graph\n",
    "            )\n",
    "\n",
    "            # Take back to input space\n",
    "            z_pred_ = F.relu(z_pred_)\n",
    "            Dz_pred_ = th.matmul(z_pred_, self.D)\n",
    "            Dz_norm_ = Dz_pred_.norm(dim=-1, keepdim=True) + self.eps\n",
    "\n",
    "            # Compute projection\n",
    "            proj_scale = (Dz_pred_ * x_input).sum(dim=-1, keepdim=True) / Dz_norm_.pow(\n",
    "                2\n",
    "            )\n",
    "\n",
    "            # Add the projection to the reconstructed\n",
    "            z_pred = z_pred + (z_pred_ * proj_scale)\n",
    "\n",
    "            # Remove the projection from the input\n",
    "            x_input = x_input - proj_scale * Dz_pred_\n",
    "\n",
    "            # Add the attention graph if return_graph is True\n",
    "            if return_graph:\n",
    "                attn_graphs.append(attn_graphs_)\n",
    "\n",
    "        ### Novel part (identified using the residual target signal) ###\n",
    "        z_novel: th.Tensor\n",
    "        if self.sae_diff_type == \"relu\":\n",
    "            z_novel = F.relu(th.matmul(x_input * self.lam, E))\n",
    "\n",
    "        elif self.sae_diff_type == \"topk\":\n",
    "            kval = self.kval_topk if inf_k is None else inf_k\n",
    "            assert (\n",
    "                kval is not None\n",
    "            ), \"kval_topk must be set when using topk sae_diff_type\"\n",
    "            z_novel = F.relu(th.matmul(x_input * self.lam, E))\n",
    "            _, topk_indices = th.topk(z_novel, kval, dim=-1)\n",
    "            mask = th.zeros_like(z_novel)\n",
    "            mask.scatter_(-1, topk_indices, 1)\n",
    "            z_novel = z_novel * mask\n",
    "\n",
    "        else:  # self.sae_diff_type == \"nullify\"\n",
    "            z_novel = th.zeros_like(z_pred)\n",
    "\n",
    "        ### Reconstruction ###\n",
    "        x_recons = th.matmul(z_novel + z_pred, self.D) + self.b\n",
    "        x_recons = x_recons / self.activation_scaling_factor\n",
    "\n",
    "        ### Compute the predicted vs. novel reconstructions ###\n",
    "        with th.no_grad():\n",
    "            x_pred_recons = th.matmul(z_pred, self.D) / self.activation_scaling_factor\n",
    "            x_novel_recons = th.matmul(z_novel, self.D) / self.activation_scaling_factor\n",
    "\n",
    "        ### Return the dictionary ###\n",
    "        results_dict = {\n",
    "            \"novel_codes\": z_novel,\n",
    "            \"novel_recons\": x_novel_recons,\n",
    "            \"pred_codes\": z_pred,\n",
    "            \"pred_recons\": x_pred_recons,\n",
    "            \"attn_graphs\": th.stack(attn_graphs, dim=1) if return_graph else None,\n",
    "        }\n",
    "\n",
    "        return x_recons, results_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download_weights"
   },
   "source": [
    "### Load Pretrained SAE Weights from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297,
     "referenced_widgets": [
      "ace083b69fd84512b9008d575ec976c7",
      "ba59279455634f48bdaefee26e0e9169",
      "d2da9a43492841f3b61343cf4c57c381",
      "62c59052b8eb41e28afcf1251a0d71fc",
      "312f7f2ae0ac4982ad71007264fb8f1d",
      "26698c5e1d8d466fad38c11643449ae3",
      "33324d024ebc4f38903a00c7dd307634",
      "507d22f86af74d84bc300e4651066151",
      "263778314f6743de9ad51bfb30243a36",
      "73b68075e8944032af86adecb0749355",
      "0389d096740141b7ae05ed973d4d116a",
      "df40c5ef1d66473cbf2970b8155737e0",
      "491e301994f9481d83534e31f36aeafb",
      "bcf57d8faad14e69816b5f2a00f6dac3",
      "3fd9d9b3130d4c1389306f616ef9570f",
      "12f08c0f4c8946e3a7d65a7abb405e1b",
      "5fec9f1d32df415da25706d4c775b1bf",
      "1b08f622470a487d883cb5b2b90d6afb",
      "276206b4dc884736b51bb205030294c2",
      "9113797754684ee0b3539351f8490c65",
      "01178baa48ae40cbaa3c8ab57da1b3b9",
      "8bad82f188844d79879146e6e9a4abc9"
     ]
    },
    "id": "download",
    "outputId": "3dcf1822-edaf-4da4-c476-bf228f8396dc"
   },
   "outputs": [],
   "source": [
    "# Download SAE weights from HuggingFace\n",
    "repo_id = \"canrager/temporalSAEs\"\n",
    "sae_path = \"gemma-2-2B/layer_12/temporal\"\n",
    "local_dir = \"./pretrained_sae\"\n",
    "\n",
    "# Create local directory\n",
    "os.makedirs(local_dir, exist_ok=True)\n",
    "\n",
    "# Download config file\n",
    "config_path = hf_hub_download(\n",
    "    repo_id=repo_id,\n",
    "    filename=f\"{sae_path}/conf.yaml\",\n",
    "    local_dir=local_dir,\n",
    "    local_dir_use_symlinks=False,\n",
    ")\n",
    "\n",
    "# Download safetensors weights\n",
    "weights_path = hf_hub_download(\n",
    "    repo_id=repo_id,\n",
    "    filename=f\"{sae_path}/latest_ckpt.safetensors\",\n",
    "    local_dir=local_dir,\n",
    "    local_dir_use_symlinks=False,\n",
    ")\n",
    "\n",
    "print(f\"Downloaded config to: {config_path}\")\n",
    "print(f\"Downloaded weights to: {weights_path}\")\n",
    "\n",
    "# Load configuration\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "init_sae",
    "outputId": "94c0e9b7-8450-4b1b-eccc-214fe2182d33"
   },
   "outputs": [],
   "source": [
    "# Initialize SAE with config parameters\n",
    "sae = TemporalSAE(\n",
    "    dimin=config['llm']['dimin'],\n",
    "    width=config['llm']['dimin'] * config['sae']['exp_factor'],\n",
    "    n_heads=config['sae']['n_heads'],\n",
    "    sae_diff_type=config['sae']['sae_diff_type'],\n",
    "    kval_topk=config['sae']['kval_topk'],\n",
    "    tied_weights=config['sae']['tied_weights'],\n",
    "    n_attn_layers=config['sae']['n_attn_layers'],\n",
    "    bottleneck_factor=config['sae']['bottleneck_factor'],\n",
    "    activation_scaling_factor=config['sae']['scaling_factor'],\n",
    ")\n",
    "\n",
    "# Load weights from safetensors\n",
    "state_dict = load_file(weights_path)\n",
    "sae.load_state_dict(state_dict)\n",
    "\n",
    "# Move to GPU if available\n",
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "sae = sae.to(device)\n",
    "sae.eval()\n",
    "\n",
    "print(f\"Loaded SAE with {sae.width} features\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "load_model"
   },
   "source": [
    "### Load Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437,
     "referenced_widgets": [
      "607e5e7e7c6c49cbbce5fd7c965514c4",
      "99f764c88cea47a483ccb92bb24656f8",
      "18d9293af9254a44948159b66bdff928",
      "feab33667b7d4cc8b2ae5395388c1a4d",
      "951ff85c95a04aceb85df79b529cdb6e",
      "e7d32f3ac8a146d0a739e7eab8845f50",
      "41491ff69b994884b894d00d04cec6d5",
      "22079e121daa4a4eaea22b2e7a371a9e",
      "d42beedb831943e09676b6adb55bcfb1",
      "91a6e5fb3a15483babf34651dbdf39a4",
      "5eb36c7b7d2c49588f77f58e8146957d",
      "347bbaef5caf435895a20baab75a15da",
      "103ddd4c7b764cdf94a9079db380d17f",
      "8ce90566ee0e4f298a5298b2d9788a58",
      "b89916c7b8b24f668c8859a87b7692b7",
      "cd95884472164c7c81b45f6f61308c60",
      "67b18a30304f465893a59de70d5341c9",
      "b0d164a9ccd9485ca99358379bd2a972",
      "5c7aff81975c40119d296ab155fb6624",
      "da22ea77a03940eb8f276cf584c40d3b",
      "ce398edc20cb4ebb97a00a9b0f1d5803",
      "dfb59f082e944846b2c2eebab67aefc7",
      "4f58da2891ca4072aa93673762be39b8",
      "06e8dc58bf0345ac9a00a23ca16daa71",
      "3c0ea5e34c09499e932e3294e025ae8b",
      "a339e0bf9d0a496698614ab534f4d387",
      "5421424c46eb4ee791946eaf6400090a",
      "f178fdd3f6fb4e45af48c1aee5be340a",
      "41f858b17e3b43f18e9f132794020755",
      "c1e209dc2e144e8d8e3ff703ca070312",
      "401718f5817444659019f8223709984f",
      "8bec1f8f54a84a42a0dd961adaaa5918",
      "21f3525e4a9e4d05867728a9daba2f39",
      "1d9f5ee980264ba6b212b0b183d1f43e",
      "72af1c352d914ebdb9f1544328d9f8bd",
      "29579661c9554a23ac99c2607a4b01ae",
      "731dd3c70bfb480f8d2b9034831b3ecd",
      "31fac04a98af4258ba286c26c67ed9e4",
      "3cd3d6d14ead48539416ef6ead5d998b",
      "6cf5f945956d42aa833d1b7dcfe35d6a",
      "9044443f67c749148bc47658b9ef5004",
      "554ca52a97ce4792bbe6f7cb9b07e0a0",
      "d311b3e6417348e9b99bd0a4dde412cd",
      "b994cb97ac4449d594123055d189691a",
      "0f918d01c7444e0583b4f91232e91678",
      "6e3adc041c714ca3b41c1b366307dbc7",
      "af4ee4ce247d45bfa05c324718130990",
      "bd42ea9ea9b7483d9779ba835d56f903",
      "54da6ab6a93648d38db0fc8b9b759f6e",
      "a97f85a645504f4a93c70538412437f7",
      "fc536749992b4890a5705b6e0e87c9f8",
      "37e12ffb811c4f88aca513b5bf5cebd8",
      "91dc3420165d4244a2b3a0fa20d059dd",
      "cca2906d410b4df2833415c6c12ca58e",
      "46d04c6dd16f4fa3a988f8c8c932f34c",
      "172cb3d1ca7543db9726a6ed0ebe67f5",
      "f301252438534d69b9cc515546afa98b",
      "f53e2eaa64424cb391e1afb3d5578e4d",
      "ac04262829ef42548206a35530405951",
      "f448bf33e99440be91833f54da7e127c",
      "65519b5077de4f199bb7e116540290dc",
      "cd998c4347c24b809f86671bb80fed46",
      "724ac2d400e24ca0ba056587983ca4f0",
      "43b75d7b21ef4af89fd539945b93e091",
      "be91e761a13f45de99016b6d9febdc3a",
      "ecf2cc1a8b764b6285d51d9039e34b31",
      "1a2a1492a6cc4d2f94d5aa2bead7ac6b",
      "48d67167cdc4432bae57f17ee005cbad",
      "9ea9bb1f061c4161804aca39aca21890",
      "c554c017e742420593350500439fe0f4",
      "c03de33bc83f4cfebd5559fa6d874b75",
      "50f82d6a98304dd48079fad5aa373cec",
      "bb4df628b5664e9f8cb6bbc63e6b76c3",
      "6dea852385d9420fae6cfef8c2fe06f1",
      "973c9a99dd644d8cb95f0872da208ecf",
      "dd3812090e984b8faee7c386c4aa5eae",
      "4a243864a8a447179a02033f2171230f",
      "bc4d33363a9346ba94557434c0b7c080",
      "6ce15213b78540d695e878e6e217504b",
      "56c300c6b47a4d979758563b44531a9d",
      "6972497380604d93bd38e38bd0b7afc2",
      "7b7cbe8aa1d54f98953bd646a711f2ed",
      "5d0b756b63304d78977a944ec342840c",
      "96316f1bf7e5409b84c00de3428c291d",
      "658b1f57e1d5497fa4f9b8070dd3ea35",
      "ddeed3af4e5749ee881da8723f681574",
      "923f7ba980224de9ac94157a22c3e5b3",
      "da26a6e70c994e279503d20c2d4f0538",
      "3ffd0a4418964322886f8dfd5377e610",
      "73260fa5a37846b4a0e98c59ba788de6",
      "ad6de22823a94c699af4321d8f0c2ea9",
      "62364ffa8be24431ac16bc5bc0a88029",
      "bcd33f068d7f4e0f952a9e19097ee1d0",
      "419fbaf898894c1eacfebb1d3bcf3c02",
      "92027fcf76334462ba788516b20f9968",
      "ee45e860db8247b9a4a5ddc84a402dc9",
      "52caab91881d4b26a6b42981199a3da0",
      "705409daee55454880ae8fc734b85077",
      "0e50973974514ca09def1d3d6951c881",
      "26a47f0e94fb460dbc4cb58445290ac6",
      "3ea2f559939f474ea9e49bf8b2816049",
      "b464ee6a49624e6dac284cf832020386",
      "837c98402c964ebbbcc77ce47e2c757b",
      "cda44470657345c089cab1c8e824ad1f",
      "4428d4deae9a4dcdbd997153e1bed335",
      "ecc9d18e49934140a8b0f4916cf9075e",
      "83982efcdbfd40b5a4820166b4cf7003",
      "0d2abe3f01134e55b3928b2b016cdfaa",
      "01a8eb4f13c94553a565fc4be7689f30",
      "9d479cea3d4b4020b3bef4a9b593497b",
      "9e804a682c6e4b68be44cc68f4898620",
      "6183cf508d1149dbbdd8612907b110d0",
      "ad1ab524d8b849b4ab3a461fec3f872b",
      "55aebb153c184fdbb847a48190bb0162",
      "11cafd54f11b4273afe6372fb1e31e68",
      "a24a6f47b20144629147093e591d84a7",
      "720ab43630754639b78fc013b847cba1",
      "366dcb57b49a4f10922165fe68eacfb4",
      "4770d4f3dbd84cc0b2ce50e100b4c8eb",
      "7c3576c6925e4990ab2f670178a55f15",
      "3a374ef468f5462bb1534ea49a6b5afb",
      "e46751963e164fce8752a465c5cc6107",
      "d347fd88ebde414b9f480903fe6bec6b",
      "d9dcee88812548df8940c93bb4ae1c31",
      "607c1bbb78dd432bac6c834a61ca3509",
      "6d62f6e4d0844404aa706f0623af501d",
      "294b601bb0434d229d7a3ca890bdd481",
      "ee44b1f24a7043e78cd69c08ad53cd22",
      "d6ea491be23d45b598b2f17603e6e679",
      "b5ea6171e5d1436c9e61a94c299b5f41",
      "9475926114344f009b67c5f25c1ef073",
      "b700b183617044879d781aea31192081"
     ]
    },
    "id": "load_gemma",
    "outputId": "d7b72b0b-a2ea-4701-ab9c-978a7d11ef59"
   },
   "outputs": [],
   "source": [
    "# Disable gradients\n",
    "th.set_grad_enabled(False)\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_name = config['llm']['model_hf_name']\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map='auto',\n",
    "    torch_dtype=th.bfloat16,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(config['llm']['tokenizer_hf_name'])\n",
    "\n",
    "print(f\"Loaded model: {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hook_fn"
   },
   "outputs": [],
   "source": [
    "## Cache Model Activations\n",
    "def gather_residual_activations(model, target_layer, inputs):\n",
    "    \"\"\"Hook to extract residual stream activations at a specific layer.\"\"\"\n",
    "    target_act = None\n",
    "\n",
    "    def gather_target_act_hook(mod, inputs, outputs):\n",
    "        nonlocal target_act\n",
    "        target_act = outputs[0]\n",
    "        return outputs\n",
    "\n",
    "    handle = model.model.layers[target_layer].register_forward_hook(gather_target_act_hook)\n",
    "    _ = model.forward(inputs)\n",
    "    handle.remove()\n",
    "    return target_act"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction and sparsity\n",
    "\n",
    "The TFA provides two codes: The predictive code and the novel code. First, we check the sparsity and reconstruction (variance explained) of each code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Configuration\n",
    "num_sequences = 50\n",
    "num_tokens = 500\n",
    "target_layer = 12\n",
    "\n",
    "# Load FineWeb dataset\n",
    "print(\"Loading FineWeb dataset...\")\n",
    "dataset = load_dataset(\"HuggingFaceFW/fineweb\", name=\"sample-10BT\", split=\"train\", streaming=True)\n",
    "\n",
    "# Stream and tokenize sequences\n",
    "activations = []\n",
    "\n",
    "print(f\"Streaming {num_sequences} sequences with up to {num_tokens} tokens each...\")\n",
    "\n",
    "for idx, example in enumerate(dataset):\n",
    "    if len(activations) >= num_sequences:\n",
    "        break\n",
    "    \n",
    "    # Get text from the example\n",
    "    text = example['text']\n",
    "    \n",
    "    # Tokenize with truncation to num_tokens\n",
    "    tokens = tokenizer.encode(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        add_special_tokens=True,\n",
    "        truncation=True,\n",
    "        max_length=num_tokens\n",
    "    ).to(device)\n",
    "\n",
    "    if tokens.shape[1] < num_tokens:\n",
    "        continue\n",
    "    \n",
    "    # Extract activations at target layer\n",
    "    with th.no_grad():\n",
    "        single_act = gather_residual_activations(model, target_layer, tokens)\n",
    "    \n",
    "    # Store activations\n",
    "    activations.append(single_act)\n",
    "    \n",
    "    if (idx + 1) % 10 == 0:\n",
    "        print(f\"Processed {idx + 1}/{num_sequences} sequences\")\n",
    "\n",
    "activations = th.cat(activations, dim=0)\n",
    "\n",
    "# Stack all activations into a single tensor\n",
    "# Shape: [num_sequences, max_seq_len, d_model]\n",
    "print(f\"\\nCaching complete!\")\n",
    "print(f\"Total sequences processed: {len(activations)}\")\n",
    "print(f\"Activation shape: {activations.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sae_inference",
    "outputId": "45761ff6-4a28-41fc-adf5-7971d8ee265f"
   },
   "outputs": [],
   "source": [
    "def compute_variance_explained(reconstruction: th.Tensor, target: th.Tensor) -> th.Tensor:\n",
    "    \"\"\"Compute variance explained by a reconstruction.\"\"\"\n",
    "    return reconstruction.var(dim=(0,1)).sum() / target.var(dim=(0,1)).sum()\n",
    "\n",
    "def compute_l0_sparsity(codes: th.Tensor) -> th.Tensor:\n",
    "    \"\"\"Compute L0 sparsity (number of non-zero elements) for codes.\"\"\"\n",
    "    return (codes != 0.0).sum(-1)\n",
    "\n",
    "\n",
    "# Run SAE\n",
    "recons, results = sae(activations)\n",
    "\n",
    "# Get codes and reconstructions\n",
    "novel_codes = results['novel_codes']\n",
    "pred_codes = results['pred_codes']\n",
    "total_codes = novel_codes + pred_codes\n",
    "novel_recons = results['novel_recons']\n",
    "pred_recons = results['pred_recons']\n",
    "\n",
    "# Check reconstruction quality for tokens except BOS\n",
    "variance_explained_total = compute_variance_explained(recons[:, 1:], activations[:, 1:])\n",
    "variance_explained_novel = compute_variance_explained(novel_recons[:, 1:], activations[:, 1:])\n",
    "variance_explained_pred = compute_variance_explained(pred_recons[:, 1:], activations[:, 1:])\n",
    "\n",
    "print(f\"Variance explained (novel): {variance_explained_novel:.4f}\")\n",
    "print(f\"Variance explained (pred): {variance_explained_pred:.4f}\")\n",
    "print(f\"Variance explained (total): {variance_explained_total:.4f}\")\n",
    "\n",
    "# Check sparsity (L0)\n",
    "l0_novel = compute_l0_sparsity(novel_codes)\n",
    "l0_pred = compute_l0_sparsity(pred_codes)\n",
    "l0_total = compute_l0_sparsity(total_codes)\n",
    "\n",
    "print(f\"\\nL0 (novel) mean: {l0_novel.float().mean():.2f}, std: {l0_novel.float().std():.2f}\")\n",
    "print(f\"L0 (predictive): {l0_pred.float().mean():.2f}, std: {l0_pred.float().std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictive code is not sparse, the average number of non-zero dimensions is larger than the embedding dim (d_model = 2304 for Gemma-2-2B). However, the effective rank of predictive codes is significantly smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_effective_rank(tensor: th.Tensor, threshold: float = 0.999) -> tuple[int, th.Tensor]:\n",
    "    \"\"\"\n",
    "    Compute effective rank of a tensor using SVD.\n",
    "    \n",
    "    Args:\n",
    "        tensor: Input tensor of shape (batch, seq_len, d_model)\n",
    "        threshold: Cumulative variance threshold for determining effective rank (default: 0.99)\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (effective_rank, singular_values)\n",
    "    \"\"\"\n",
    "    # Reshape to (batch * seq_len, d_model)\n",
    "    B, L, D = tensor.shape\n",
    "    X = tensor.reshape(B * L, D).cpu().float()\n",
    "    \n",
    "    # Compute SVD\n",
    "    _, S, _ = th.linalg.svd(X, full_matrices=False)\n",
    "    \n",
    "    # Compute explained variance ratio\n",
    "    variance = S ** 2\n",
    "    variance_ratio = variance / variance.sum()\n",
    "    cumsum_variance = th.cumsum(variance_ratio, dim=0)\n",
    "    \n",
    "    # Find effective rank (first index where cumsum exceeds threshold)\n",
    "    effective_rank = (cumsum_variance < threshold).sum().item() + 1\n",
    "    \n",
    "    return effective_rank, S\n",
    "\n",
    "\n",
    "thresh = 0.999\n",
    "\n",
    "# Compute effective rank of predictable reconstructions\n",
    "pred_recons_flat = pred_recons  # Shape: (batch, seq_len, d_model)\n",
    "effective_rank, singular_values = compute_effective_rank(pred_recons_flat, threshold=thresh)\n",
    "\n",
    "print(f\"\\nEffective rank of predictable reconstructions: {effective_rank}\")\n",
    "print(f\"Total dimensions (d_model): {pred_recons_flat.shape[-1]}\")\n",
    "print(f\"Rank compression ratio: {effective_rank / pred_recons_flat.shape[-1]:.4f}\")\n",
    "\n",
    "# Plot singular value spectrum\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot singular values\n",
    "axes[0].plot(singular_values.numpy())\n",
    "axes[0].axvline(x=effective_rank, color='r', linestyle='--', label=f'Effective rank: {effective_rank}')\n",
    "axes[0].set_xlabel('Singular value index')\n",
    "axes[0].set_ylabel('Singular value')\n",
    "axes[0].set_title('Singular Value Spectrum')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot cumulative explained variance\n",
    "variance = singular_values ** 2\n",
    "variance_ratio = variance / variance.sum()\n",
    "cumsum_variance = th.cumsum(variance_ratio, dim=0)\n",
    "\n",
    "axes[1].plot(cumsum_variance.numpy())\n",
    "axes[1].axhline(y=thresh, color='r', linestyle='--', label=f'{thresh:.4f} threshold')\n",
    "axes[1].axvline(x=effective_rank, color='r', linestyle='--', alpha=0.5, label=f'Effective rank: {effective_rank}')\n",
    "axes[1].set_xlabel('Number of components')\n",
    "axes[1].set_ylabel('Cumulative explained variance')\n",
    "axes[1].set_title('Cumulative Explained Variance')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "909af161"
   },
   "source": [
    "# Analyzing contextual information via predictive codes\n",
    "\n",
    "The predictive code reveals slow-moving, contextual information. We visualize this via a similarity matrix, and UMAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example prompt\n",
    "prompt = \"\"\"Once upon a time, a little girl named Alice loved looking at the night sky. 'I wish I could count all the stars!' Alice said to her best friend Maya. The two girls stood on a big grass field as the moon rose from the trees. Suddenly, Maya had a striking idea. She opened her laptop and started typing:\n",
    "```python\n",
    "array = []\n",
    "for i in range(1, 6):\n",
    "    s = int(input(f'num_stars:'))\n",
    "    array.append(s)\n",
    "tot = sum(array)\n",
    "avg = tot / len(array)\n",
    "print(f'Avg / night: [avg:.1f]')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize\n",
    "inputs = tokenizer.encode(prompt, return_tensors=\"pt\", add_special_tokens=True).to(device)\n",
    "token_list = tokenizer.convert_ids_to_tokens(inputs[0])\n",
    "print(f\"Input shape: {inputs.shape}\")\n",
    "print(f\"Tokens: {token_list}\")\n",
    "\n",
    "# Extract activations at layer 12\n",
    "target_layer = 12\n",
    "activations = gather_residual_activations(model, target_layer, inputs)\n",
    "print(f\"\\nActivations shape: {activations.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run SAE\n",
    "recons, results = sae(activations)\n",
    "\n",
    "# Get codes\n",
    "novel_codes = results['novel_codes']\n",
    "pred_codes = results['pred_codes']\n",
    "total_codes = novel_codes + pred_codes\n",
    "\n",
    "# Check reconstruction quality\n",
    "variance_explained = 1 - th.mean((recons[:, 1:] - activations[:, 1:]) ** 2) / (activations[:, 1:].to(th.float32).var())\n",
    "print(f\"\\nVariance explained: {variance_explained:.4f}\")\n",
    "\n",
    "# Check sparsity (L0)\n",
    "l0_novel = (novel_codes != 0.0).sum(-1)\n",
    "l0_pred = (pred_codes != 0.0).sum(-1) # Pred codes can be negative\n",
    "l0_total = (total_codes != 0.0).sum(-1)\n",
    "\n",
    "print(f\"\\nL0 (novel): {l0_novel.squeeze().tolist()}\")\n",
    "print(f\"L0 (predictable): {l0_pred.squeeze().tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "similarity"
   },
   "source": [
    "## Compute Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sim_matrix",
    "outputId": "b8d1528c-4282-4373-8952-ada41e783c46"
   },
   "outputs": [],
   "source": [
    "# Compute pairwise cosine similarity between predictable codes across tokens\n",
    "# Extract pred_codes for batch_idx = 0\n",
    "pred_LD = pred_codes[0]  # Shape: [L, D] where L=sequence_length, D=width\n",
    "\n",
    "# Center the predictions\n",
    "pred_centered_LD = pred_LD - th.mean(pred_LD, dim=0, keepdim=True)\n",
    "\n",
    "# Normalize along the D dimension\n",
    "pred_LD_normalized = F.normalize(pred_centered_LD.float(), p=2, dim=-1)  # L x D, normalized along D\n",
    "\n",
    "# Compute cosine similarity: pred_LD @ pred_LD.T -> L x L\n",
    "cosine_sim_LL = pred_LD_normalized @ pred_LD_normalized.T\n",
    "cosine_sim_np = cosine_sim_LL.cpu().numpy()\n",
    "\n",
    "print(f\"Similarity matrix shape: {cosine_sim_LL.shape}\")\n",
    "print(f\"Min similarity: {cosine_sim_LL.min():.4f}\")\n",
    "print(f\"Max similarity: {cosine_sim_LL.max():.4f}\")\n",
    "print(f\"Mean similarity: {cosine_sim_LL.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "mjyjml9nto",
    "outputId": "391b2495-200b-4fcd-b3d7-970ce3972410"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "vmin = None\n",
    "vmax = None\n",
    "\n",
    "# Get token strings for labels\n",
    "token_str_L = tokenizer.convert_ids_to_tokens(inputs[0])\n",
    "\n",
    "# Create a large figure to accommodate token labels\n",
    "L = len(token_str_L)\n",
    "fig, ax = plt.subplots(figsize=(max(20, L * 0.5), max(18, L * 0.5)))\n",
    "\n",
    "# Plot heatmap\n",
    "im = ax.imshow(cosine_sim_np, cmap='magma', aspect='auto', vmin=vmin, vmax=vmax)\n",
    "\n",
    "# Set tick labels to tokens\n",
    "ax.set_xticks(range(L))\n",
    "ax.set_yticks(range(L))\n",
    "ax.set_xticklabels(token_str_L, rotation=90, ha='center', fontsize=8)\n",
    "ax.set_yticklabels(token_str_L, fontsize=8)\n",
    "\n",
    "# Labels and title\n",
    "ax.set_xlabel('Token Position', fontsize=14)\n",
    "ax.set_ylabel('Token Position', fontsize=14)\n",
    "ax.set_title('Cosine Similarity of Prediction Representations (pred_LD @ pred_LD.T)', fontsize=16)\n",
    "\n",
    "# Colorbar\n",
    "cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "cbar.set_label('Cosine Similarity')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try the interactive webviewer on Neuronpedia!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 621
    },
    "id": "2cf5a3b1",
    "outputId": "2cfce238-9797-4300-e86d-937abb427027"
   },
   "outputs": [],
   "source": [
    "html_similarity_viewer = \"https://www.neuronpedia.org/gemma-2-2b/12-temporal-res?simMatrixDemo=alice-maya\"\n",
    "IFrame(html_similarity_viewer, width=1200, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "umap_section"
   },
   "source": [
    "## UMAP Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "umap_compute",
    "outputId": "b37e46cd-e441-46a0-f3dd-adaf91ea1840"
   },
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "import numpy as np\n",
    "\n",
    "# UMAP Configuration\n",
    "n_components = 3  # 3D visualization\n",
    "n_neighbors = 15\n",
    "min_dist = 0.1\n",
    "metric = 'euclidean'\n",
    "random_state = 42\n",
    "\n",
    "# Position subsampling (since we only have 20 tokens, use all of them)\n",
    "min_p = 0\n",
    "max_p = 30 # Last position index\n",
    "num_p = min(pred_codes.shape[1], 20)  # Sample up to 20 positions\n",
    "\n",
    "# Compute position indices\n",
    "ps = th.linspace(min_p, max_p, num_p, dtype=th.int)\n",
    "print(f\"Position indices: {ps.tolist()}\")\n",
    "\n",
    "# Subsample pred_codes at selected positions\n",
    "# pred_codes shape: (batch, seq_len, width)\n",
    "act_BLD_subsampled = pred_codes[:, ps, :]  # (batch, num_p, width)\n",
    "\n",
    "# Flatten for UMAP: (batch * num_p, width)\n",
    "B, L, D = act_BLD_subsampled.shape\n",
    "X = act_BLD_subsampled.reshape(B * L, D).cpu().float().numpy()\n",
    "\n",
    "# Initialize and fit UMAP\n",
    "reducer = UMAP(\n",
    "    n_components=n_components,\n",
    "    n_neighbors=n_neighbors,\n",
    "    min_dist=min_dist,\n",
    "    metric=metric,\n",
    "    random_state=random_state,\n",
    ")\n",
    "\n",
    "embedding_np = reducer.fit_transform(X)\n",
    "embedding = th.from_numpy(embedding_np).reshape(B, L, -1)\n",
    "print(f\"UMAP embedding shape: {embedding.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 817
    },
    "id": "plotly_viz",
    "outputId": "468912ad-3d0c-4934-9aa8-88d4225e8869"
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Generate hover texts with token context\n",
    "hover_window = 500  # Number of tokens to show before current position\n",
    "hover_texts = []\n",
    "\n",
    "token_strs_L = tokenizer.convert_ids_to_tokens(inputs[0])\n",
    "\n",
    "for b_idx in range(B):\n",
    "    for l_idx_in_seq, pos_idx in enumerate(ps.tolist()):\n",
    "        # Show previous hover_window tokens + current token (bolded)\n",
    "        start_idx = max(0, pos_idx - hover_window)\n",
    "        end_idx = min(len(token_strs_L), pos_idx + 1)\n",
    "\n",
    "        story_str = \"\"\n",
    "        token_count = 0\n",
    "        for i in range(start_idx, end_idx):\n",
    "            t = token_strs_L[i]\n",
    "\n",
    "            # Add linebreak every 15 tokens\n",
    "            if token_count > 0 and token_count % 15 == 0:\n",
    "                story_str += \"<br>\"\n",
    "\n",
    "            if i == pos_idx:\n",
    "                story_str += f\"<b>{t}</b>\"  # Bold the current token\n",
    "            else:\n",
    "                story_str += t\n",
    "\n",
    "            token_count += 1\n",
    "\n",
    "        hover_texts.append(f\"Position: {pos_idx}<br>Story: {story_str}\")\n",
    "\n",
    "# Flatten embedding and position labels for plotting\n",
    "embedding_flat = embedding.reshape(-1, n_components).numpy()\n",
    "pos_labels_flat = ps.repeat(B).numpy()\n",
    "\n",
    "# Create 3D scatter plot\n",
    "if n_components == 3:\n",
    "    traces = [\n",
    "        go.Scatter3d(\n",
    "            x=embedding_flat[:, 0],\n",
    "            y=embedding_flat[:, 1],\n",
    "            z=embedding_flat[:, 2],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(\n",
    "                size=5,\n",
    "                color=pos_labels_flat,\n",
    "                colorscale=\"Viridis\",\n",
    "                showscale=True,\n",
    "                colorbar=dict(title=\"Position Index\"),\n",
    "                opacity=0.8,\n",
    "            ),\n",
    "            text=hover_texts,\n",
    "            hovertemplate=\"%{text}<br>UMAP1: %{x:.2f}<br>UMAP2: %{y:.2f}<br>UMAP3: %{z:.2f}<extra></extra>\",\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Add sequence connection lines\n",
    "    for b in range(B):\n",
    "        traces.append(\n",
    "            go.Scatter3d(\n",
    "                x=embedding[b, :, 0].numpy(),\n",
    "                y=embedding[b, :, 1].numpy(),\n",
    "                z=embedding[b, :, 2].numpy(),\n",
    "                mode=\"lines\",\n",
    "                line=dict(color=\"black\", width=2),\n",
    "                opacity=0.3,\n",
    "                showlegend=False,\n",
    "                hoverinfo=\"skip\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "    fig = go.Figure(data=traces)\n",
    "    fig.update_layout(\n",
    "        title=\"UMAP of Temporal Predictive Codes (colored by position)\",\n",
    "        scene=dict(xaxis_title=\"UMAP 1\", yaxis_title=\"UMAP 2\", zaxis_title=\"UMAP 3\"),\n",
    "        width=1000,\n",
    "        height=800,\n",
    "    )\n",
    "\n",
    "elif n_components == 2:\n",
    "    traces = [\n",
    "        go.Scatter(\n",
    "            x=embedding_flat[:, 0],\n",
    "            y=embedding_flat[:, 1],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(\n",
    "                size=8,\n",
    "                color=pos_labels_flat,\n",
    "                colorscale=\"Viridis\",\n",
    "                showscale=True,\n",
    "                colorbar=dict(title=\"Position Index\"),\n",
    "                opacity=0.6,\n",
    "            ),\n",
    "            text=hover_texts,\n",
    "            hovertemplate=\"%{text}<br>UMAP1: %{x:.2f}<br>UMAP2: %{y:.2f}<extra></extra>\",\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Add sequence connection lines\n",
    "    for b in range(B):\n",
    "        traces.append(\n",
    "            go.Scatter(\n",
    "                x=embedding[b, :, 0].numpy(),\n",
    "                y=embedding[b, :, 1].numpy(),\n",
    "                mode=\"lines\",\n",
    "                line=dict(color=\"black\", width=2),\n",
    "                opacity=0.3,\n",
    "                showlegend=False,\n",
    "                hoverinfo=\"skip\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "    fig = go.Figure(data=traces)\n",
    "    fig.update_layout(\n",
    "        title=\"UMAP of Temporal Predictive Codes (colored by position)\",\n",
    "        xaxis_title=\"UMAP 1\",\n",
    "        yaxis_title=\"UMAP 2\",\n",
    "        width=1000,\n",
    "        height=800,\n",
    "    )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run_sae"
   },
   "source": [
    "# Analyzing local information via Novel Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7SDtEgeTHsys",
    "outputId": "3642d976-e4c5-41e5-a004-8ae99296361e"
   },
   "outputs": [],
   "source": [
    "val, ind = novel_codes.max(dim=-1)\n",
    "selected_feature_idx = ind[0, -2] # Token position \"_sky\"\n",
    "\n",
    "print(f\"Selected token: {token_list[-2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 639
    },
    "id": "fMq_XArHHsys",
    "outputId": "218fbe45-08d3-45e0-f624-8dae4f0f7d78"
   },
   "outputs": [],
   "source": [
    "## Feature Dashboard Visualization\n",
    "from IPython.display import IFrame\n",
    "\n",
    "html_template = \"https://neuronpedia.org/{}/{}/{}?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\"\n",
    "\n",
    "def get_dashboard_html(sae_release=\"gemma-2-2b\", sae_id=\"12-temporal-res\", feature_idx=0):\n",
    "    \"\"\"Generate Neuronpedia dashboard URL for a specific feature.\"\"\"\n",
    "    return html_template.format(sae_release, sae_id, feature_idx)\n",
    "\n",
    "example_feature_idx = 0 # Interpretation: proper noun (last token)\n",
    "example_feature_idx = 1 # Interpretation: optimism\n",
    "example_feature_idx = 2 # Interpretation: manipulation\n",
    "\n",
    "html = get_dashboard_html(\n",
    "    sae_release=\"gemma-2-2b\",\n",
    "    sae_id=\"12-temporal-res\",  # Adjust this to match your SAE on Neuronpedia if available\n",
    "    feature_idx=selected_feature_idx\n",
    ")\n",
    "\n",
    "print(f\"Displaying dashboard for feature {example_feature_idx}\")\n",
    "IFrame(html, width=1200, height=600)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
